#!/bin/bash

#this script (map10x1.sh) is used for short read polishing of the long-read assembly 
#resulting from Canu (mtDNApipe.sh) and Arrow polishing (ArrowPolish.sh).
#In the VGP pipeline it uses 10x data (currently with random barcodes) but it can be used
#with any short read data containing mitogenomic reads using information from Canu
#intermediate files.

#it requires the following software (and their dependencies) installed:
#bowtie2/2.1.0, aws-cli/1.16.101, samtools/1.7, freebayes/1.1.0-46-g8d2b3a0-dirty, bcftools/1.9

#reads are aligned to the reference, and if aligned reads are >1.5M they are downsampled to
#about this number. A final round of freebayes and bcftools consensus is performed to
#obtain the polished contig using the aligned outcome of the script.

#in addition, the script provides the fw and rv reads (extracted from the alignment)
#required for the final polishing step (map10x2.sh).

#required positional arguments are:
#the species name (e.g. Calypte_anna)
#the VGP species ID (e.g. bCalAnn1)
#the filename of the mitocontig generated by the script ArrowPolish.sh

set -e

SPECIES=$1
ABBR=$2
CONTIG=$3
NPROC=$4

#define working directory
W_URL=${SPECIES}/assembly_MT/intermediates

if ! [[ -e "${W_URL}/bowtie2_round1" ]]; then

mkdir ${W_URL}/bowtie2_round1

fi

#record 10x raw data files available in the cloud at the time of the analysis

if ! [[ -e "${W_URL}/bowtie2_round1/log" ]]; then

mkdir ${W_URL}/bowtie2_round1/log

dw_date=`date "+%Y%m%d-%H%M%S"`; aws s3 --no-sign-request ls s3://genomeark/species/${SPECIES}/${ABBR}/genomic_data/10x/ > ${W_URL}/bowtie2_round1/log/file_list_$dw_date.txt

fi

if ! [[ -e "${W_URL}/bowtie2_round1/${ABBR}.1.bt2" ]]; then

bowtie2-build ${W_URL}/arrow/arrow_round2/${CONTIG} ${W_URL}/bowtie2_round1/${ABBR}

fi

#determine fw and rv reads
if ! [[ -e "${W_URL}/bowtie2_round1/p_fw.txt" ]]; then

grep -o -E "${ABBR}.*_R1_.*" ${W_URL}/bowtie2_round1/log/file_list_${dw_date}.txt | sort | uniq > ${W_URL}/bowtie2_round1/p_fw.txt

fi

if ! [[ -e "${W_URL}/bowtie2_round1/p_rv.txt" ]]; then

grep -o -E "${ABBR}.*_R2_.*" ${W_URL}/bowtie2_round1/log/file_list_${dw_date}.txt | sort | uniq > ${W_URL}/bowtie2_round1/p_rv.txt

fi

mapfile -t p1 < ${W_URL}/bowtie2_round1/p_fw.txt
mapfile -t p2 < ${W_URL}/bowtie2_round1/p_rv.txt

echo "--Following PE files found:"

for ((i=0; i<${#p1[*]}; i++));
do

echo ${p1[i]} ${p2[i]} $i

done

if ! [[ -e "${W_URL}/bowtie2_round1/aligned_raw_reads" ]]; then

mkdir ${W_URL}/bowtie2_round1/aligned_raw_reads

fi

#for each 10x PE raw data do
for ((i=0; i<${#p1[*]}; i++));
do

if ! [[ -e "${W_URL}/bowtie2_round1/aligned_raw_reads/aligned_${ABBR}_${i}.bam" ]]; then

echo "--Retrieve and align:"

echo "s3://genomeark/species/${SPECIES}/${ABBR}/genomic_data/10x/${p1[i]}"
echo "s3://genomeark/species/${SPECIES}/${ABBR}/genomic_data/10x/${p2[i]}"

#download
aws s3 --no-sign-request cp s3://genomeark/species/${SPECIES}/${ABBR}/genomic_data/10x/${p1[i]} ${W_URL}
aws s3 --no-sign-request cp s3://genomeark/species/${SPECIES}/${ABBR}/genomic_data/10x/${p2[i]} ${W_URL}

#align
bowtie2 -x ${W_URL}/bowtie2_round1/${ABBR} -1 ${W_URL}/${p1[i]} -2 ${W_URL}/${p2[i]} -p ${NPROC} | samtools view -bSF4 - > "${W_URL}/bowtie2_round1/aligned_raw_reads/aligned_${ABBR}_${i}.bam"

#remove
rm ${W_URL}/${p1[i]} ${W_URL}/${p2[i]}

fi

done

#generate single alignment file out of all raw data
if ! [[ -e "${W_URL}/bowtie2_round1/aligned_${ABBR}_all.bam" ]]; then

samtools merge ${W_URL}/bowtie2_round1/aligned_${ABBR}_all.bam ${W_URL}/bowtie2_round1/aligned_raw_reads/*.bam

#downsample the file if >1.5M reads
READ_N=$(bedtools bamtobed -i ${W_URL}/bowtie2_round1/aligned_${ABBR}_all.bam | cut -f 4 | wc -l)

if (("$READ_N" >= "1500000")); then

N=$(awk "BEGIN {printf \"%.2f\",1500000/${READ_N}}")
N_READ_N=$(awk "BEGIN {printf \"%.0f\",$N*${READ_N}}")

echo "The number of reads is above 1.5M ($READ_N). Downsampling by $N ($N_READ_N)"

samtools view -s $N -b ${W_URL}/bowtie2_round1/aligned_${ABBR}_all.bam > ${W_URL}/bowtie2_round1/aligned_${ABBR}_all_sub.bam
mv ${W_URL}/bowtie2_round1/aligned_${ABBR}_all.bam ${W_URL}/bowtie2_round1/aligned_${ABBR}_all_o.bam
mv ${W_URL}/bowtie2_round1/aligned_${ABBR}_all_sub.bam ${W_URL}/bowtie2_round1/aligned_${ABBR}_all.bam

fi

fi

#split the fw and rv reads in the alignment for next step (map10x2.sh)
if ! [[ -e "${W_URL}/bowtie2_round1/fq" ]]; then

mkdir ${W_URL}/bowtie2_round1/fq
samtools fastq ${W_URL}/bowtie2_round1/aligned_${ABBR}_all.bam -1 ${W_URL}/bowtie2_round1/fq/aligned_${ABBR}_all_1.fq -2 ${W_URL}/bowtie2_round1/fq/aligned_${ABBR}_all_2.fq -s ${W_URL}/bowtie2_round1/fq/aligned_${ABBR}_all_s.fq

fi

#sort and index the alignment
if ! [[ -e "${W_URL}/bowtie2_round1/aligned_${ABBR}_all_sorted.bam" ]]; then

samtools sort ${W_URL}/bowtie2_round1/aligned_${ABBR}_all.bam -o ${W_URL}/bowtie2_round1/aligned_${ABBR}_all_sorted.bam -@ ${NPROC}
samtools index ${W_URL}/bowtie2_round1/aligned_${ABBR}_all_sorted.bam

rm ${W_URL}/bowtie2_round1/aligned_${ABBR}_all.bam

fi

#call variants and consensus

if ! [[ -e "${W_URL}/freebayes_round1/" ]]; then

mkdir ${W_URL}/freebayes_round1/

~/miniconda3/bin/freebayes -f ${W_URL}/arrow/arrow_round2/${CONTIG} -b ${W_URL}/bowtie2_round1/aligned_${ABBR}_all_sorted.bam --ploidy 1 -v ${W_URL}/freebayes_round1/aligned_${ABBR}_all_sorted.vcf

bgzip ${W_URL}/freebayes_round1/aligned_${ABBR}_all_sorted.vcf

tabix -p vcf ${W_URL}/freebayes_round1/aligned_${ABBR}_all_sorted.vcf.gz

/home/gformenti/bin/bcftools/bcftools consensus ${W_URL}/freebayes_round1/aligned_${ABBR}_all_sorted.vcf.gz -f ${W_URL}/arrow/arrow_round2/${CONTIG} -o ${W_URL}/freebayes_round1/${CONTIG%.*}_10x1.fasta

fi